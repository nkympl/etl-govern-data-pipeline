# Arquitetura do Projeto â€” ETL govern data pipeline

Este documento descreve a arquitetura tÃ©cnica e o fluxo de dados do projeto **ETL govern data pipeline**, uma simulaÃ§Ã£o do projeto de pipeline corporativo do qual fiz parte durante meu estÃ¡gio no MinistÃ©rio da JustiÃ§a e SeguranÃ§a PÃºblica para tratamento e integraÃ§Ã£o de dados de compras pÃºblicas utilizando Node.js, JSON, PostgreSQL e Power BI.

---

## MÃ³dulo 1 â€” Estrutura Inicial do Projeto

### Objetivo

Definir a **arquitetura de diretÃ³rios e arquivos** que organiza o projeto de forma modular, clara e escalÃ¡vel.

### DescriÃ§Ã£o

O projeto Ã© estruturado para refletir as etapas clÃ¡ssicas de um pipeline ETL (_Extract, Transform, Load_), bem como separar documentaÃ§Ã£o, dados e scripts de forma lÃ³gica.

### Estrutura

```text
ğŸ“¦ etl-govern-data-pipeline
â”œâ”€â”€ ğŸ“ data
â”‚ â”œâ”€â”€ ğŸ“ raw â†’ planilhas originais (entrada)
â”‚ â””â”€â”€ ğŸ“ processed â†’ dados limpos e padronizados
â”‚
â”œâ”€â”€ ğŸ“ etl
â”‚ â”œâ”€â”€ extract.js â†’ cÃ³digo de extraÃ§Ã£o dos arquivos Excel
â”‚ â”œâ”€â”€ transform.js â†’ cÃ³digo de limpeza e padronizaÃ§Ã£o
â”‚ â””â”€â”€ load.js â†’ cÃ³digo de inserÃ§Ã£o no banco
â”‚
â”œâ”€â”€ ğŸ“ db
â”‚ â””â”€â”€ schema.sql â†’ script SQL de criaÃ§Ã£o das tabelas
â”‚
â”œâ”€â”€ ğŸ“ docs
â”‚ â””â”€â”€ arquitetura.md â†’ documentaÃ§Ã£o tÃ©cnica
â”‚
â”œâ”€â”€ .env.example â†’ variÃ¡veis de ambiente
â”œâ”€â”€ package.json â†’ dependÃªncias e scripts
â””â”€â”€ README.md â†’ guia geral do projeto
```

### Tecnologias instaladas

- `xlsx` â†’ leitura e escrita de planilhas Excel
- `pg` â†’ integraÃ§Ã£o com PostgreSQL
- `dotenv` â†’ gerenciamento de variÃ¡veis de ambiente

### Resultados

Ambiente inicial funcional com estrutura modular e dependÃªncias configuradas.

## MÃ³dulo 1.5 â€” ConfiguraÃ§Ã£o de Ambiente

### Objetivo

Definir variÃ¡veis de ambiente que parametrizam a execuÃ§Ã£o do pipeline sem expor dados sensÃ­veis.

### Estrutura do `.env.example`

```bash
# ConfiguraÃ§Ãµes do Banco de Dados PostgreSQL
DB_HOST=localhost
DB_PORT=5432
DB_NAME=etl_compras
DB_USER=postgres
DB_PASSWORD=senha_segura

# Caminhos internos
RAW_DATA_PATH=./data/raw
PROCESSED_DATA_PATH=./data/processed

# Ambiente de execuÃ§Ã£o
NODE_ENV=development
```

## MÃ³dulo 2 - ExtraÃ§Ã£o dos Dados (E)

### Objetivo

Ler planilhas Excel contendo dados de compras pÃºblicas e converter seu conteÃºdo em objetos manipulÃ¡veis (JSON) dentro do Node.js.

### DescriÃ§Ã£o

A etapa de ExtraÃ§Ã£o (Extract) coleta dados brutos das fontes originais â€” neste caso, arquivos Excel localizados em `data/raw/`.
O script `etl/extract.js` lÃª cada planilha, seleciona a primeira aba e transforma as linhas em um array de objetos JavaScript.

### Ferramentas e mÃ©todos

- Biblioteca `xlsx`
- FunÃ§Ãµes principais:
  - `readFile()` â€” carrega a planilha;
  - `sheet_to_json()` â€” converte a aba em JSON.

### Fluxo lÃ³gico

```text
ğŸ“ data/raw/compras_sp.xlsx
   â†“
Node.js + XLSX â†’ Leitura e ConversÃ£o
   â†“
Array de Objetos JSON â†’ SaÃ­da no Console
```

### MÃ³dulo 3 - Etapa de TransformaÃ§Ã£o (T)

ResponsÃ¡vel por:

- Padronizar nomes de colunas (remoÃ§Ã£o de acentos e uso de snake_case);
- Calcular o campo `valor_total`;
- Gerar arquivos JSON limpos prontos para carga no banco de dados.

**Entrada:** planilhas Excel convertidas em JSON.  
**SaÃ­da:** arquivos JSON padronizados em `/data/processed`.
